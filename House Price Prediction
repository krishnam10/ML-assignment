import pandas as pd

# Load the dataset
train_url = "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/train.csv"
test_url = "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/download/test.csv"
train_data = pd.read_csv(train_url)
test_data = pd.read_csv(test_url)
# Separate features and target
X = train_data.drop('SalePrice', axis=1)
y = train_data['SalePrice']

# Concatenate train and test data for preprocessing
all_data = pd.concat([X, test_data], ignore_index=True)

# Handle missing values
# You can use techniques like filling with mean/median, mode, or more advanced imputation methods.
all_data.fillna(method='ffill', inplace=True)

# Convert categorical variables to numerical using one-hot encoding
all_data_encoded = pd.get_dummies(all_data)

# Split back into train and test sets
X_train_encoded = all_data_encoded[:len(X)]
X_test_encoded = all_data_encoded[len(X):]
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Split the data into train and validation sets
X_train, X_valid, y_train, y_valid = train_test_split(X_train_encoded, y, test_size=0.2, random_state=42)

# Initialize the model (Gradient Boosting Regressor)
model = GradientBoostingRegressor(random_state=42)

# Train the model
model.fit(X_train, y_train)
# Make predictions on the validation set
y_pred = model.predict(X_valid)

# Calculate mean squared error
mse = mean_squared_error(y_valid, y_pred)
print("Mean Squared Error:", mse)
# Make predictions on the test data
test_predictions = model.predict(X_test_encoded)

# Create a DataFrame to store the predictions
submission = pd.DataFrame({
    'Id': test_data['Id'],
    'SalePrice': test_predictions
})

# Save the predictions to a CSV file
submission.to_csv('house_price_predictions.csv', index=False)
